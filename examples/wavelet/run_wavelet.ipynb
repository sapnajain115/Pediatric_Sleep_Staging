{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, cohen_kappa_score, accuracy_score\n",
    "\n",
    "import sleep_study as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y, y_hat, verbose=True):\n",
    "    cf = confusion_matrix(y, y_hat)\n",
    "    ncf = 100*confusion_matrix(y, y_hat, normalize='true') # percentage\n",
    "    precision,recall,mf,support = precision_recall_fscore_support(y,y_hat,average='macro')\n",
    "    kp = cohen_kappa_score(y, y_hat)\n",
    "    acc = 100*accuracy_score(y, y_hat) # percentage\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nConfusion Matrix')\n",
    "        print(cf)\n",
    "        print('\\nNormalized Confusion Matrix')\n",
    "        print(np.round(ncf))\n",
    "        print('Accuracy: ', acc)\n",
    "        print('Precision: ',precision)\n",
    "        print('Recall: ',recall)\n",
    "        print('Macro-F1 Score: ',mf)\n",
    "        print('Kohen Kappa: ',kp)\n",
    "        \n",
    "    return {'confusion matrix': cf,\n",
    "            'normalized confusion matrix': ncf,\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'Macro-F1 Score': mf,\n",
    "            'Kohen Kappa': kp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all_metrics(res, keys):\n",
    "    ncf_name = 'normalized confusion matrix'\n",
    "    \n",
    "    for i, k in enumerate(keys):\n",
    "        all_metrics = res[k]\n",
    "        num_trials = len(all_metrics)\n",
    "                \n",
    "        means = pd.DataFrame(data = np.round(np.mean([all_metrics[rr][ncf_name] for rr in range(num_trials)], axis=0), 1), dtype='str')\n",
    "        stds = pd.DataFrame(data = np.round(np.std([all_metrics[rr][ncf_name] for rr in range(num_trials)], axis=0), 1), dtype='str')\n",
    "        tbl = (means + \" \" + u\"\\u00B1\" + \" \" + stds).to_numpy()\n",
    "        print(ncf_name)\n",
    "        print(tbl) # I want normalized CF to print nicely with mean \\pm standard deviation.\n",
    "\n",
    "        for j in ['accuracy', 'precision', 'recall', 'Macro-F1 Score', 'Kohen Kappa']:\n",
    "            m = str(np.round(np.mean([all_metrics[rr][j] for rr in range(num_trials)]), 3))\n",
    "            s = str(np.round(np.std([all_metrics[rr][j] for rr in range(num_trials)]), 3))\n",
    "            print(j, \":\", m + \" \" + u\"\\u00B1\" + \" \" + s)\n",
    "        print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_npz_file_names(path):\n",
    "    files = []\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if (entry.name.endswith('.npz') or entry.name.endswith('.NPZ')) and entry.is_file():\n",
    "                files.append(path+entry.name)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(fn, verbose=False):   \n",
    "    X = np.load(fn, allow_pickle=True)\n",
    "    features, labels, studies = X[\"features\"], X[\"labels\"], X[\"studies\"]\n",
    "    if verbose:\n",
    "        print(fn)\n",
    "        print(features.shape, labels.shape, len(studies))\n",
    "        \n",
    "    return features, labels, studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier(idxs, data, clf, verbose=True):\n",
    "    \n",
    "    train_idx, test_idx = idxs\n",
    "    X, y = data\n",
    "    \n",
    "    X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print('train set class distribution', sorted(Counter(y_train).items()))\n",
    "        print('test set class distribution', sorted(Counter(y_test).items()))\n",
    "\n",
    "    t = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if verbose:\n",
    "        print('training took', np.around((time.time()-t)/60, 2), 'minutes.')\n",
    "\n",
    "    y_hat = rf.predict(X_test)\n",
    "\n",
    "    metrics = get_metrics(y_test, y_hat, verbose=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(metrics)\n",
    "        print( )\n",
    "\n",
    "    return metrics, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature and label extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age information stored in /home/harlinl/sleep_study_harlin/age_file.csv\n",
      "total number of sleep study files available: 3984\n"
     ]
    }
   ],
   "source": [
    "ss.init()\n",
    "print('total number of sleep study files available:', len(ss.data.study_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = list(zip(range(0, 18), range(1, 19))) + [(18, 100)]\n",
    "\n",
    "tmp = np.load('study_lists.npz', allow_pickle=True) \n",
    "study_lists = tmp[\"study_lists\"] # filenames that are in each age group\n",
    "num_segments = tmp[\"num_segments\"]\n",
    "all_labels = tmp[\"all_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(230824, 7, 12) (230824,)\n",
      "features from 0 to 1 y.o. pts saved in wavelet_features3/6_dbwt_0_1yrs_2020-12-12T14:25.npz\n",
      " \n",
      "\n",
      "(186088, 7, 12) (186088,)\n",
      "features from 1 to 2 y.o. pts saved in wavelet_features3/6_dbwt_1_2yrs_2020-12-12T14:35.npz\n",
      " \n",
      "\n",
      "(278268, 7, 12) (278268,)\n",
      "features from 2 to 3 y.o. pts saved in wavelet_features3/6_dbwt_2_3yrs_2020-12-12T14:47.npz\n",
      " \n",
      "\n",
      "(261939, 7, 12) (261939,)\n",
      "features from 3 to 4 y.o. pts saved in wavelet_features3/6_dbwt_3_4yrs_2020-12-12T14:57.npz\n",
      " \n",
      "\n",
      "(244173, 7, 12) (244173,)\n",
      "features from 4 to 5 y.o. pts saved in wavelet_features3/6_dbwt_4_5yrs_2020-12-12T15:07.npz\n",
      " \n",
      "\n",
      "(222787, 7, 12) (222787,)\n",
      "features from 5 to 6 y.o. pts saved in wavelet_features3/6_dbwt_5_6yrs_2020-12-12T15:16.npz\n",
      " \n",
      "\n",
      "(229099, 7, 12) (229099,)\n",
      "features from 6 to 7 y.o. pts saved in wavelet_features3/6_dbwt_6_7yrs_2020-12-12T15:25.npz\n",
      " \n",
      "\n",
      "(221072, 7, 12) (221072,)\n",
      "features from 7 to 8 y.o. pts saved in wavelet_features3/6_dbwt_7_8yrs_2020-12-12T15:35.npz\n",
      " \n",
      "\n",
      "(200103, 7, 12) (200103,)\n",
      "features from 8 to 9 y.o. pts saved in wavelet_features3/6_dbwt_8_9yrs_2020-12-12T15:43.npz\n",
      " \n",
      "\n",
      "(177709, 7, 12) (177709,)\n",
      "features from 9 to 10 y.o. pts saved in wavelet_features3/6_dbwt_9_10yrs_2020-12-12T15:51.npz\n",
      " \n",
      "\n",
      "(172860, 7, 12) (172860,)\n",
      "features from 10 to 11 y.o. pts saved in wavelet_features3/6_dbwt_10_11yrs_2020-12-12T15:58.npz\n",
      " \n",
      "\n",
      "(165875, 7, 12) (165875,)\n",
      "features from 11 to 12 y.o. pts saved in wavelet_features3/6_dbwt_11_12yrs_2020-12-12T16:05.npz\n",
      " \n",
      "\n",
      "(162748, 7, 12) (162748,)\n",
      "features from 12 to 13 y.o. pts saved in wavelet_features3/6_dbwt_12_13yrs_2020-12-12T16:12.npz\n",
      " \n",
      "\n",
      "(145688, 7, 12) (145688,)\n",
      "features from 13 to 14 y.o. pts saved in wavelet_features3/6_dbwt_13_14yrs_2020-12-12T16:18.npz\n",
      " \n",
      "\n",
      "(131107, 7, 12) (131107,)\n",
      "features from 14 to 15 y.o. pts saved in wavelet_features3/6_dbwt_14_15yrs_2020-12-12T16:23.npz\n",
      " \n",
      "\n",
      "(152950, 7, 12) (152950,)\n",
      "features from 15 to 16 y.o. pts saved in wavelet_features3/6_dbwt_15_16yrs_2020-12-12T16:30.npz\n",
      " \n",
      "\n",
      "(144366, 7, 12) (144366,)\n",
      "features from 16 to 17 y.o. pts saved in wavelet_features3/6_dbwt_16_17yrs_2020-12-12T16:36.npz\n",
      " \n",
      "\n",
      "(120514, 7, 12) (120514,)\n",
      "features from 17 to 18 y.o. pts saved in wavelet_features3/6_dbwt_17_18yrs_2020-12-12T16:40.npz\n",
      " \n",
      "\n",
      "(196135, 7, 12) (196135,)\n",
      "features from 18 to 100 y.o. pts saved in wavelet_features3/6_dbwt_18_100yrs_2020-12-12T16:49.npz\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# this can be parallelized to speed up the process\n",
    "for i, study_list in enumerate(study_lists):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for j, name in enumerate(study_lists[i]):\n",
    "        features, labels = ss.data.get_demo_wavelet_features_and_labels(name)\n",
    "        all_features.extend(features)\n",
    "        all_labels.extend(labels)\n",
    "    \n",
    "    features = np.array(all_features)\n",
    "    labels = np.array(all_labels)\n",
    "    print( )\n",
    "    print(features.shape, labels.shape)\n",
    "    \n",
    "    fn = 'wavelet_features3/6_dbwt_' + str(age_groups[i][0]) + '_' + str(age_groups[i][1]) + 'yrs_' + \\\n",
    "        datetime.now().isoformat(timespec='minutes') + '.npz'\n",
    "    \n",
    "    np.savez(fn, labels=labels, features=features, studies=study_lists[i])\n",
    "    print('features from', age_groups[i][0], 'to', age_groups[i][1], 'y.o. pts saved in', fn)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wavelet_features3/6_dbwt_0_1yrs_2020-12-12T14:25.npz', 'wavelet_features3/6_dbwt_1_2yrs_2020-12-12T14:35.npz', 'wavelet_features3/6_dbwt_2_3yrs_2020-12-12T14:47.npz', 'wavelet_features3/6_dbwt_3_4yrs_2020-12-12T14:57.npz', 'wavelet_features3/6_dbwt_4_5yrs_2020-12-12T15:07.npz', 'wavelet_features3/6_dbwt_5_6yrs_2020-12-12T15:16.npz', 'wavelet_features3/6_dbwt_6_7yrs_2020-12-12T15:25.npz', 'wavelet_features3/6_dbwt_7_8yrs_2020-12-12T15:35.npz', 'wavelet_features3/6_dbwt_8_9yrs_2020-12-12T15:43.npz', 'wavelet_features3/6_dbwt_9_10yrs_2020-12-12T15:51.npz', 'wavelet_features3/6_dbwt_10_11yrs_2020-12-12T15:58.npz', 'wavelet_features3/6_dbwt_11_12yrs_2020-12-12T16:05.npz', 'wavelet_features3/6_dbwt_12_13yrs_2020-12-12T16:12.npz', 'wavelet_features3/6_dbwt_13_14yrs_2020-12-12T16:18.npz', 'wavelet_features3/6_dbwt_14_15yrs_2020-12-12T16:23.npz', 'wavelet_features3/6_dbwt_15_16yrs_2020-12-12T16:30.npz', 'wavelet_features3/6_dbwt_16_17yrs_2020-12-12T16:36.npz', 'wavelet_features3/6_dbwt_17_18yrs_2020-12-12T16:40.npz', 'wavelet_features3/6_dbwt_18_100yrs_2020-12-12T16:49.npz']\n"
     ]
    }
   ],
   "source": [
    "seed = 0 # for reproducibility\n",
    "num_trials = 3\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=seed, bootstrap=True, n_jobs=-1)\n",
    "cv = StratifiedKFold(n_splits=num_trials, shuffle=True, random_state=seed)\n",
    "\n",
    "feature_files = get_npz_file_names('wavelet_features3/')\n",
    "print(feature_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavelet_features3/6_dbwt_0_1yrs_2020-12-12T14:25.npz\n",
      "(230824, 7, 12) (230824,) 242\n",
      "wavelet_features3/6_dbwt_1_2yrs_2020-12-12T14:35.npz\n",
      "(186088, 7, 12) (186088,) 192\n",
      "wavelet_features3/6_dbwt_2_3yrs_2020-12-12T14:47.npz\n",
      "(278268, 7, 12) (278268,) 295\n",
      "wavelet_features3/6_dbwt_3_4yrs_2020-12-12T14:57.npz\n",
      "(261939, 7, 12) (261939,) 277\n",
      "wavelet_features3/6_dbwt_4_5yrs_2020-12-12T15:07.npz\n",
      "(244173, 7, 12) (244173,) 257\n",
      "wavelet_features3/6_dbwt_5_6yrs_2020-12-12T15:16.npz\n",
      "(222787, 7, 12) (222787,) 237\n",
      "wavelet_features3/6_dbwt_6_7yrs_2020-12-12T15:25.npz\n",
      "(229099, 7, 12) (229099,) 242\n",
      "wavelet_features3/6_dbwt_7_8yrs_2020-12-12T15:35.npz\n",
      "(221072, 7, 12) (221072,) 236\n",
      "wavelet_features3/6_dbwt_8_9yrs_2020-12-12T15:43.npz\n",
      "(200103, 7, 12) (200103,) 214\n",
      "wavelet_features3/6_dbwt_9_10yrs_2020-12-12T15:51.npz\n",
      "(177709, 7, 12) (177709,) 192\n",
      "wavelet_features3/6_dbwt_10_11yrs_2020-12-12T15:58.npz\n",
      "(172860, 7, 12) (172860,) 189\n",
      "wavelet_features3/6_dbwt_11_12yrs_2020-12-12T16:05.npz\n",
      "(165875, 7, 12) (165875,) 182\n",
      "wavelet_features3/6_dbwt_12_13yrs_2020-12-12T16:12.npz\n",
      "(162748, 7, 12) (162748,) 179\n",
      "wavelet_features3/6_dbwt_13_14yrs_2020-12-12T16:18.npz\n",
      "(145688, 7, 12) (145688,) 163\n",
      "wavelet_features3/6_dbwt_14_15yrs_2020-12-12T16:23.npz\n",
      "(131107, 7, 12) (131107,) 144\n",
      "wavelet_features3/6_dbwt_15_16yrs_2020-12-12T16:30.npz\n",
      "(152950, 7, 12) (152950,) 168\n",
      "wavelet_features3/6_dbwt_16_17yrs_2020-12-12T16:36.npz\n",
      "(144366, 7, 12) (144366,) 163\n",
      "wavelet_features3/6_dbwt_17_18yrs_2020-12-12T16:40.npz\n",
      "(120514, 7, 12) (120514,) 134\n",
      "wavelet_features3/6_dbwt_18_100yrs_2020-12-12T16:49.npz\n",
      "(196135, 7, 12) (196135,) 222\n",
      "(3644305, 84) (3644305,) 3928\n",
      "train set class distribution [(0, 441096), (1, 85068), (2, 917119), (3, 580800), (4, 405453)]\n",
      "test set class distribution [(0, 220549), (1, 42534), (2, 458559), (3, 290400), (4, 202727)]\n",
      "training took 53.34 minutes.\n",
      "{'confusion matrix': array([[139159,     69,  75068,   3247,   3006],\n",
      "       [ 10239,    404,  28796,    911,   2184],\n",
      "       [ 20186,     62, 406417,  26638,   5256],\n",
      "       [  5045,      0,  79085, 205276,    994],\n",
      "       [ 13650,     30, 155388,   3005,  30654]]), 'normalized confusion matrix': array([[6.30966361e+01, 3.12855647e-02, 3.40368807e+01, 1.47223519e+00,\n",
      "        1.36296243e+00],\n",
      "       [2.40725067e+01, 9.49828373e-01, 6.77011332e+01, 2.14181596e+00,\n",
      "        5.13471576e+00],\n",
      "       [4.40205077e+00, 1.35206157e-02, 8.86291622e+01, 5.80906710e+00,\n",
      "        1.14619929e+00],\n",
      "       [1.73725895e+00, 0.00000000e+00, 2.72331267e+01, 7.06873278e+01,\n",
      "        3.42286501e-01],\n",
      "       [6.73319291e+00, 1.47982262e-02, 7.66488924e+01, 1.48228899e+00,\n",
      "        1.51208275e+01]]), 'accuracy': 64.36697018116202, 'precision': 0.7173414525367476, 'recall': 0.47696756411634766, 'Macro-F1 Score': 0.4801651849750064, 'Kohen Kappa': 0.4817631610445249}\n",
      "\n",
      "train set class distribution [(0, 441097), (1, 85068), (2, 917118), (3, 580800), (4, 405454)]\n",
      "test set class distribution [(0, 220548), (1, 42534), (2, 458560), (3, 290400), (4, 202726)]\n",
      "training took 54.46 minutes.\n",
      "{'confusion matrix': array([[139356,     72,  74679,   3289,   3152],\n",
      "       [ 10068,    395,  29082,    896,   2093],\n",
      "       [ 20291,     64, 406112,  26697,   5396],\n",
      "       [  5003,      2,  78444, 205866,   1085],\n",
      "       [ 13586,     36, 155329,   3003,  30772]]), 'normalized confusion matrix': array([[6.31862452e+01, 3.26459546e-02, 3.38606562e+01, 1.49128534e+00,\n",
      "        1.42916735e+00],\n",
      "       [2.36704754e+01, 9.28668830e-01, 6.83735365e+01, 2.10655005e+00,\n",
      "        4.92076927e+00],\n",
      "       [4.42493894e+00, 1.39567341e-02, 8.85624564e+01, 5.82192080e+00,\n",
      "        1.17672715e+00],\n",
      "       [1.72279614e+00, 6.88705234e-04, 2.70123967e+01, 7.08904959e+01,\n",
      "        3.73622590e-01],\n",
      "       [6.70165642e+00, 1.77579590e-02, 7.66201671e+01, 1.48130975e+00,\n",
      "        1.51791087e+01]]), 'accuracy': 64.41567443330743, 'precision': 0.7126230567712131, 'recall': 0.4774939500030075, 'Macro-F1 Score': 0.48064714782989537, 'Kohen Kappa': 0.4825854740092499}\n",
      "\n",
      "train set class distribution [(0, 441097), (1, 85068), (2, 917119), (3, 580800), (4, 405453)]\n",
      "test set class distribution [(0, 220548), (1, 42534), (2, 458559), (3, 290400), (4, 202727)]\n",
      "training took 53.01 minutes.\n",
      "{'confusion matrix': array([[139157,     68,  74932,   3380,   3011],\n",
      "       [ 10197,    382,  28963,    878,   2114],\n",
      "       [ 20109,     64, 406618,  26708,   5060],\n",
      "       [  5014,      4,  79230, 205028,   1124],\n",
      "       [ 13654,     28, 155450,   2978,  30617]]), 'normalized confusion matrix': array([[6.30960154e+01, 3.08322905e-02, 3.39753704e+01, 1.53254620e+00,\n",
      "        1.36523569e+00],\n",
      "       [2.39737622e+01, 8.98105045e-01, 6.80937603e+01, 2.06423097e+00,\n",
      "        4.97014153e+00],\n",
      "       [4.38525904e+00, 1.39567646e-02, 8.86729952e+01, 5.82433231e+00,\n",
      "        1.10345670e+00],\n",
      "       [1.72658402e+00, 1.37741047e-03, 2.72830579e+01, 7.06019284e+01,\n",
      "        3.87052342e-01],\n",
      "       [6.73516601e+00, 1.38116778e-02, 7.66794754e+01, 1.46897059e+00,\n",
      "        1.51025764e+01]]), 'accuracy': 64.35813258169462, 'precision': 0.7146381612174209, 'recall': 0.476743240716358, 'Macro-F1 Score': 0.47984503749963575, 'Kohen Kappa': 0.48158155372245126}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenate all features and labels \n",
    "X, y = [], []\n",
    "all_studies = []\n",
    "\n",
    "for fn in feature_files:\n",
    "    features, labels, studies = load_features(fn)\n",
    "    print(fn)\n",
    "    print(features.shape, labels.shape, len(studies))   \n",
    "    \n",
    "    X.extend(features.reshape(len(features), -1))\n",
    "    y.extend(labels)\n",
    "    all_studies.extend(studies)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(X.shape, y.shape, len(all_studies))\n",
    "\n",
    "\n",
    "# train and test RF classifier on all data\n",
    "all_metrics = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "\n",
    "    metrics, y_hat = train_test_classifier((train_idx, test_idx), (X, y), rf)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "res = {'all ages': all_metrics}\n",
    "\n",
    "np.savez('wavelet' + '_all_results' + datetime.now().isoformat(timespec='minutes') + '.npz', results=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized confusion matrix\n",
      "[['63.1 ± 0.0' '0.0 ± 0.0' '34.0 ± 0.1' '1.5 ± 0.0' '1.4 ± 0.0']\n",
      " ['23.9 ± 0.2' '0.9 ± 0.0' '68.1 ± 0.3' '2.1 ± 0.0' '5.0 ± 0.1']\n",
      " ['4.4 ± 0.0' '0.0 ± 0.0' '88.6 ± 0.0' '5.8 ± 0.0' '1.1 ± 0.0']\n",
      " ['1.7 ± 0.0' '0.0 ± 0.0' '27.2 ± 0.1' '70.7 ± 0.1' '0.4 ± 0.0']\n",
      " ['6.7 ± 0.0' '0.0 ± 0.0' '76.6 ± 0.0' '1.5 ± 0.0' '15.1 ± 0.0']]\n",
      "accuracy : 64.38 ± 0.025\n",
      "precision : 0.715 ± 0.002\n",
      "recall : 0.477 ± 0.0\n",
      "Macro-F1 Score : 0.48 ± 0.0\n",
      "Kohen Kappa : 0.482 ± 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_all_metrics(res, ['all ages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavelet_features3/6_dbwt_0_1yrs_2020-12-12T14:25.npz\n",
      "(230824, 84) (230824,) 242\n",
      "wavelet_features3/6_dbwt_1_2yrs_2020-12-12T14:35.npz\n",
      "(186088, 84) (186088,) 192\n",
      "wavelet_features3/6_dbwt_2_3yrs_2020-12-12T14:47.npz\n",
      "(278268, 84) (278268,) 295\n",
      "wavelet_features3/6_dbwt_3_4yrs_2020-12-12T14:57.npz\n",
      "(261939, 84) (261939,) 277\n",
      "wavelet_features3/6_dbwt_4_5yrs_2020-12-12T15:07.npz\n",
      "(244173, 84) (244173,) 257\n",
      "wavelet_features3/6_dbwt_5_6yrs_2020-12-12T15:16.npz\n",
      "(222787, 84) (222787,) 237\n",
      "wavelet_features3/6_dbwt_6_7yrs_2020-12-12T15:25.npz\n",
      "(229099, 84) (229099,) 242\n",
      "wavelet_features3/6_dbwt_7_8yrs_2020-12-12T15:35.npz\n",
      "(221072, 84) (221072,) 236\n",
      "wavelet_features3/6_dbwt_8_9yrs_2020-12-12T15:43.npz\n",
      "(200103, 84) (200103,) 214\n",
      "wavelet_features3/6_dbwt_9_10yrs_2020-12-12T15:51.npz\n",
      "(177709, 84) (177709,) 192\n",
      "wavelet_features3/6_dbwt_10_11yrs_2020-12-12T15:58.npz\n",
      "(172860, 84) (172860,) 189\n",
      "wavelet_features3/6_dbwt_11_12yrs_2020-12-12T16:05.npz\n",
      "(165875, 84) (165875,) 182\n",
      "wavelet_features3/6_dbwt_12_13yrs_2020-12-12T16:12.npz\n",
      "(162748, 84) (162748,) 179\n",
      "wavelet_features3/6_dbwt_13_14yrs_2020-12-12T16:18.npz\n",
      "(145688, 84) (145688,) 163\n",
      "wavelet_features3/6_dbwt_14_15yrs_2020-12-12T16:23.npz\n",
      "(131107, 84) (131107,) 144\n",
      "wavelet_features3/6_dbwt_15_16yrs_2020-12-12T16:30.npz\n",
      "(152950, 84) (152950,) 168\n",
      "wavelet_features3/6_dbwt_16_17yrs_2020-12-12T16:36.npz\n",
      "(144366, 84) (144366,) 163\n",
      "wavelet_features3/6_dbwt_17_18yrs_2020-12-12T16:40.npz\n",
      "(120514, 84) (120514,) 134\n",
      "wavelet_features3/6_dbwt_18_100yrs_2020-12-12T16:49.npz\n",
      "(196135, 84) (196135,) 222\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "# train and test RF classifier on each age group\n",
    "\n",
    "for fn in feature_files:\n",
    "    X, y, studies = load_features(fn)\n",
    "    X = X.reshape(len(y), -1)\n",
    "    print(fn)\n",
    "    print(X.shape, y.shape, len(studies))\n",
    "    \n",
    "    all_metrics = []\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        \n",
    "        metrics, y_hat = train_test_classifier((train_idx, test_idx), (X, y), rf, verbose=False)\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    res[fn] = all_metrics\n",
    "        \n",
    "np.savez('wavelet' + '_age_groups_results' + datetime.now().isoformat(timespec='minutes') + '.npz', results=res)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
